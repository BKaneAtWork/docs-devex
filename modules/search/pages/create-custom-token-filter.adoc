= Create a Custom Token Filter 
:page-topic-type: guide
:description: Create a custom token filter with the Couchbase Capella UI to change how the Search Service creates tokens from Search index content and Search queries.
:page-toclevels: 3

[abstract]
{description}

Token filters can improve your search results by removing characters from your Search index or Search queries that prevent matches. 

== Prerequisites 

* You've created an index.
For more information, see xref:create-search-index-ui.adoc[].

* You've logged in to the Couchbase Capella UI. 

== Procedure 

To create a custom token filter: 

. On the *Databases* page, select the database that has the Search index you want to edit. 
. Go to menu:Data Tools[Search].
. Click the index where you want to create a custom token filter.
. Expand *Advanced Configuration*. 
. Expand *Custom Filters*. 
. Click btn:[Add Token Filter].
. In the *Name* field, enter a name for the token filter.

You can create any of the following custom token filters: 

* <<dict-compound,dict_compound>>: Use a wordlist to find and create tokens from compound words in existing tokens.
* <<edge-ngram,edge_ngram>>: Use a set character length to create tokens from the start or end of existing tokens.
* <<elision,elision>>: Use a wordlist to remove elisions from input tokens.
* <<keyword-marker,keyword_marker>>: Use a wordlist of keywords to find and create new tokens.
* <<length,length>>: Use a set character length to filter out tokens that are too long or too short.
* <<ngram,ngram>>: Use a set character length to create new tokens.
* <<normalize-unicode,normalize_unicode>>: Use Unicode Normalization to convert tokens.
* <<shingle,shingle>>: Use a set character length and separator to concatenate and create new tokens.
* <<stop-tokens,stop_tokens>>: Use a wordlist to find and remove words from tokens.
* <<truncate-token,truncate_token>>: Use a set character length to truncate existing tokens.

[#dict-compound]
=== Create a Custom `dict_compound` Token Filter

include::partial$custom-token-filters-descriptions.adoc[lines=2..3;9..27]

To create a new `dict_compound` token filter:
 
. In the *Type* field, select *dict_compound*. 
. In the *Sub Words* list, select the wordlist to use to find subwords in input tokens.
+
You can choose your own xref:create-custom-wordlist.adoc[custom wordlist] or a xref:default-wordlists-reference.adoc[default wordlist]. Each subword match creates a new token. 
. Click btn:[Submit]. 

[#edge-ngram]
=== Create a Custom `edge_ngram` Token Filter 

include::partial$custom-token-filters-descriptions.adoc[lines=31..32;38..56]

To create a new `edge_ngram` token filter:

. In the *Type* field, select *edge_ngram*.
. Do one of the following: 
.. To create new tokens starting from the end of input tokens, select *Back*. 
.. To create new tokens starting from the beginning of input tokens, clear *Back*. 
. In the *Min* box, enter the minimum character length for a new token. 
. In the *Max* box, enter the maximum character length for a new token.
. Click btn:[Submit].

[#elision]
=== Create a Custom `elision` Token Filter

include::partial$custom-token-filters-descriptions.adoc[lines=60;66..85]

To create a new `elision` token filter:

. In the *Type* field, select *elision*. 
. In the *Articles* list, select a wordlist to use to find elisions in input tokens.
+
You can choose your own xref:create-custom-wordlist.adoc[custom wordlist] or a xref:default-wordlists-reference.adoc[default wordlist].
. Click btn:[Submit]. 

[#keyword-marker]
=== Create a Custom `keyword_marker` Token Filter 

include::partial$custom-token-filters-descriptions.adoc[lines=89;95..110]

To create a new `keyword_marker` token filter:

. In the *Type* field, select *keyword_marker*. 
. In the *Articles* list, select a wordlist to use to find keywords to create tokens.
+
You can choose your own xref:create-custom-wordlist.adoc[custom wordlist] or a xref:default-wordlists-reference.adoc[default wordlist].
. Click btn:[Submit]. 

[#length]
=== Create a Custom `length` Token Filter 

include::partial$custom-token-filters-descriptions.adoc[lines=114;120..134]

To create a new `length` token filter:

. In the *Type* field, select *length*. 
. In the *Min* box, enter the minimum character length for a new token. 
. In the *Max* box, enter the maximum character length for a new token.
. Click btn:[Submit].

[#ngram]
=== Create a Custom `ngram` Token Filter

include::partial$custom-token-filters-descriptions.adoc[lines=138;144..160]

To create a new `ngram` token filter:

. In the *Type* field, select *ngram*. 
. In the *Min* box, enter the minimum character length for a new token. 
. In the *Max* box, enter the maximum character length for a new token.
. Click btn:[Submit].

[#normalize-unicode]
=== Create a Custom `normalize_unicode` Token Filter 

include::partial$custom-token-filters-descriptions.adoc[lines=164]

To create a new `normalize_unicode` token filter:

. In the *Type* field, select *normalize_unicode*. 
. In the *Form* list, select the type of Unicode normalization to apply: 
+
* *nfc*: Use canonical decomposition and canonical composition to normalize characters. The token filter separates combined unicode characters, then merges them into a single character.
* *nfd*: Use canonical decomposition to normalize characters. The token filter separates combined unicode characters.
* *nfkc*: Use compatibility decomposition to normalize characters. The token filter converts unicode characters to remove variants.
* *nfkd*: Use compatibility decomposition and canonical composition to normalize characters. The token filter removes variants, then separates combined unicode characters to merge them into a single character.
. Click btn:[Submit].

[#shingle]
=== Create a Custom `shingle` Token Filter 

include::partial$custom-token-filters-descriptions.adoc[lines=173;179..196]

To create a new `shingle` token filter:

. In the *Type* field, select *shingle*.
. In the *Min* box, enter the minimum character length for a new token before concatenation. 
. In the *Max* box, enter the maximum character length for a new token before concatenation.
. Do one of the following: 
.. To include the original token as an output token, select *Include original token*. 
.. To remove the original token from output, clear *Include original token*. 
. (Optional) In the *Separator* field, enter a character or characters to add in between concatenated tokens. 
. (Optional) In the *Filler* field, enter a character or characters to replace tokens that are removed by another token filter.
. Click btn:[Submit].

[#stop-tokens]
=== Create a Custom `stop_tokens` Token Filter

include::partial$custom-token-filters-descriptions.adoc[lines=200;206..224]

To create a new `stop_tokens` token filter:

. In the *Type* field, select *stop_tokens*. 
. In the *Stop Words* list, select a wordlist to use to remove tokens.
+
You can choose your own xref:create-custom-wordlist.adoc[custom wordlist] or a xref:default-wordlists-reference.adoc[default wordlist].
. Click btn:[Submit].

[#truncate-token]
=== Create a Custom `truncate_token` Token Filter 

include::partial$custom-token-filters-descriptions.adoc[lines=228;234..254]

To create a new `truncate_token` token filter:

. In the *Type* field, select *truncate_token*.
. In the *Length* box, enter the maximum character length for an output token. 
. Click btn:[Submit].