= Create a Custom Tokenizer 
:page-topic-type: guide

== Prerequisites 

* You've logged in to the Capella UI. 

== Procedure

=== Create a Custom Tokenizer With a Regular Expression

To create a custom tokenizer that uses a regular expression for tokens: 

. From your organization page, select the database where you want to create a tokenizer. 
. Go to menu:Data Tools[Search].
. Do one of the following: 
.. To create a custom tokenizer on an existing Search Index, click the index name.
.. To create a custom tokenizer on a new Search Index, click btn:[Add Search Index].
. Expand *Advanced Configuration*. 
. Expand *Custom Filters*. 
. In the *Name* field, enter a name for the custom tokenizer. 
. In the *Type* field, select *regexp*.
. In the *Regular Expression* field, enter a regular expression to split input strings into tokens. 
. Click btn:[Save].

=== Create a Custom Tokenizer With an Exception 

To create a custom tokenizer that uses an exception for tokens: 

. From your organization page, select the database where you want to create a tokenizer. 
. Go to menu:Data Tools[Search].
. Do one of the following: 
.. To create a custom tokenizer on an existing Search Index, click the index name.
.. To create a custom tokenizer on a new Search Index, click btn:[Add Search Index].
. Expand *Advanced Configuration*.
. Expand *Custom Filters*. 
. Click btn:[Add Tokenizer].
. In the *Name* field, enter a name for the custom tokenizer. 
. In the *Type* field, select *exception*.
. In the *New Word* field, enter ?
. To add the ? to the list of exception patterns, click btn:[Add].
. (Optional) To add additional ? to the list of exception patterns, repeat Steps 6-7.
. In the *Tokenizer for Remaining Input* field, select a tokenizer to ?:
+
For more information about the available tokenizers, see xref:guides:search/customize-index.adoc#tokenizers[Tokenizers].
. Click btn:[Save].