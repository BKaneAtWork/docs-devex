= Create a Custom Tokenizer 
:page-topic-type: guide
:description: Create a custom tokenizer to change how the Search Service creates tokens for matching Search index content to a Search query.
:page-toclevels: 3

[abstract]
{description}

== Prerequisites 

* You've created an index.
For more information, see xref:create-search-index-ui.adoc[].

* You've logged in to the Couchbase Server Web Console. 

== Procedure

You can create 2 types of custom tokenizers: 

|====
|Tokenizer Type |Description

|Regular expression |The tokenizer uses any input that matches the regular expression to create new tokens. 

|Exception |The tokenizer removes any input that matches the regular expression, and creates tokens from the remaining input. You can choose another tokenizer to apply to the remaining input.

|====

=== Create a Regular Expression Tokenizer

To create a regular expression tokenizer: 

. Go to *Search*. 
. Click the Search index where you want to create a custom tokenizer.
. Click btn:[Edit].
. Expand *Customize Index*.
. Expand *Custom Filters*. 
. In the *Name* field, enter a name for the custom tokenizer. 
. In the *Type* field, select *regexp*.
. In the *Regular Expression* field, enter the regular expression to use to split input into tokens. 
. Click btn:[Save].

=== Create an Exception Custom Tokenizer 

To create an exception custom tokenizer:

. Go to *Search*. 
. Do one of the following: 
. Click the Search index where you want to create a custom tokenizer.
. Click btn:[Edit].
. Expand *Customize Index*.
. Expand *Custom Filters*. 
. Click btn:[Add Tokenizer].
. In the *Name* field, enter a name for the custom tokenizer. 
. In the *Type* field, select *exception*.
. In the *Exception Patterns* field, enter a regular expression to use to remove content from input.
. To add the regular expression to the list of exception patterns, click btn:[Add].
. (Optional) To add additional regular expressions to the list of exception patterns, repeat Steps 5-6.
. In the *Tokenizer for Remaining Input* field, select a tokenizer to apply to input after removing any content that matches the regular expression.
+
For more information about the available tokenizers, see xref:customize-index.adoc#tokenizers[Tokenizers].
. Click btn:[Save].