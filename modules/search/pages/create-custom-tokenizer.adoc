= Create a Custom Tokenizer 
:page-topic-type: guide
:description: Create a custom tokenizer with the Couchbase Capella UI to change how the Search Service creates tokens for matching Search index content to a Search query.
:page-toclevels: 3

[abstract]
{description}

== Prerequisites 

* You've created an index.
For more information, see xref:create-search-index-ui.adoc[].

* You've logged in to the Couchbase Capella UI. 

== Procedure

You can create 2 types of custom tokenizers: 

|====
|Tokenizer Type |Description

|<<regexp,Regular expression>> |The tokenizer uses any input that matches the regular expression to create new tokens. 

|<<excep,Exception>> |The tokenizer removes any input that matches the regular expression, and creates tokens from the remaining input. You can choose another tokenizer to apply to the remaining input.

|====

[#regexp]
=== Create a Regular Expression Tokenizer

To create a regular expression tokenizer with the Capella UI:

. On the *Databases* page, select the database that has the Search index you want to edit. 
. Go to menu:Data Tools[Search].
. Click the index where you want to create a custom tokenizer.
. Expand *Advanced Configuration*. 
. Expand *Custom Filters*. 
. Click btn:[Add Tokenizer].
. In the *Name* field, enter a name for the custom tokenizer. 
. In the *Type* field, select *regexp*.
. In the *Regular Expression* field, enter the regular expression to use to split input into tokens. 
. Click btn:[Submit].

[#excep]
=== Create an Exception Custom Tokenizer 

To create an exception custom tokenizer with the Capella UI:

. On the *Databases* page, select the database that has the Search index you want to edit. 
. Go to menu:Data Tools[Search].
. Click the index where you want to create a custom tokenizer.
. Expand *Advanced Configuration*. 
. Expand *Custom Filters*. 
. Click btn:[Add Tokenizer].
. In the *Name* field, enter a name for the custom tokenizer. 
. In the *Type* field, select *exception*.
. In the *New Word* field, enter a regular expression to use to remove content from input.
. To add the regular expression to the list of exception patterns, click btn:[Add].
. (Optional) To add additional regular expressions to the list of exception patterns, repeat Steps 9-10.
. In the *Tokenizer for Remaining Input* field, select a tokenizer to apply to input after removing any content that matches the regular expression.
+
For more information about the available tokenizers, see xref:default-tokenizers-reference.adoc[].
. Click btn:[Submit].

== Next Steps

After you create a custom tokenizer, you can use it with xref:create-custom-analyzer.adoc[a custom analyzer].

To continue customizing your Search index, you can also: 

* xref:set-advanced-settings.adoc[]
* xref:set-type-identifier.adoc[]
* xref:create-type-mapping.adoc[]
* xref:create-child-field.adoc[]
* xref:create-child-mapping.adoc[]
* xref:create-custom-character-filter.adoc[]
* xref:create-custom-token-filter.adoc[]
* xref:create-custom-wordlist.adoc[]

To run a search and test the contents of your Search index, see xref:simple-search-ui.adoc[] or xref:simple-search-rest-api.adoc[].